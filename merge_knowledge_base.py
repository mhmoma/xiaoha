# -*- coding: utf-8 -*-
"""
åˆå¹¶è¯åº“.jsonå’Œknowledge_base.jsonï¼Œåˆ›å»ºç»Ÿä¸€çš„çŸ¥è¯†åº“
"""
import json
import os

def merge_knowledge_bases():
    """
    åˆå¹¶ä¸¤ä¸ªçŸ¥è¯†åº“æ–‡ä»¶
    """
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        os.chdir(script_dir)
        
        lexicon_file = os.path.join(script_dir, 'è¯åº“.json')
        kb_file = os.path.join(script_dir, 'knowledge_base.json')
        merged_file = os.path.join(script_dir, 'merged_knowledge_base.json')
        
        print("ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶...")
        
        # è¯»å–è¯åº“.json
        print(f"   è¯»å–: {lexicon_file}")
        with open(lexicon_file, 'r', encoding='utf-8') as f:
            lexicon_data = json.load(f)
        
        # è¯»å–knowledge_base.json
        print(f"   è¯»å–: {kb_file}")
        with open(kb_file, 'r', encoding='utf-8') as f:
            kb_data = json.load(f)
        
        print("âœ… æ–‡ä»¶è¯»å–å®Œæˆï¼Œå¼€å§‹åˆå¹¶...")
        
        # åˆ›å»ºåˆå¹¶åçš„çŸ¥è¯†åº“
        merged_kb = {}
        
        # å…ˆæ·»åŠ knowledge_base.jsonçš„æ‰€æœ‰åˆ†ç±»ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼Œæ›´è¯¦ç»†ï¼‰
        for category, items in kb_data.items():
            merged_kb[category] = items
            print(f"   âœ“ æ·»åŠ åˆ†ç±»: {category} ({len(items)} ä¸ªè¯æ¡)")
        
        # æ·»åŠ è¯åº“.jsonçš„åˆ†ç±»
        for category, items in lexicon_data.items():
            if category in merged_kb:
                # å¦‚æœåˆ†ç±»å·²å­˜åœ¨ï¼Œåˆå¹¶è¯æ¡ï¼ˆå»é‡ï¼‰
                print(f"   âš  åˆ†ç±» '{category}' å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆå¹¶å»é‡...")
                existing_terms = {item['term']: item for item in merged_kb[category]}
                new_count = 0
                for item in items:
                    term = item.get('term', '').strip()
                    if term and term not in existing_terms:
                        existing_terms[term] = item
                        new_count += 1
                merged_kb[category] = list(existing_terms.values())
                print(f"     æ·»åŠ äº† {new_count} ä¸ªæ–°è¯æ¡ï¼Œæ€»è®¡ {len(merged_kb[category])} ä¸ªè¯æ¡")
            else:
                # æ–°åˆ†ç±»ï¼Œç›´æ¥æ·»åŠ 
                merged_kb[category] = items
                print(f"   âœ“ æ·»åŠ åˆ†ç±»: {category} ({len(items)} ä¸ªè¯æ¡)")
        
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜åˆå¹¶åçš„çŸ¥è¯†åº“...")
        with open(merged_file, 'w', encoding='utf-8') as f:
            json.dump(merged_kb, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… åˆå¹¶å®Œæˆï¼")
        print(f"   - è¾“å‡ºæ–‡ä»¶: {merged_file}")
        print(f"   - åˆ†ç±»æ•°é‡: {len(merged_kb)}")
        total_items = 0
        for category, items in merged_kb.items():
            total_items += len(items)
        print(f"   - æ€»è®¡: {total_items} ä¸ªè¯æ¡")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        for category, items in sorted(merged_kb.items(), key=lambda x: len(x[1]), reverse=True):
            print(f"   - {category}: {len(items)} ä¸ªè¯æ¡")
        
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° - {e}")
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    merge_knowledge_bases()



